{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "\n",
    "base_path = 'F:\\Study\\weiboPredict\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "def extract_features_tt(features_t,repo,k):\n",
    "    arrive_tt = repo.arrive_tt[repo['w_id']==features_t.name].values\n",
    "    interval_tt = arrive_tt - shift(arrive_tt,1,cval=0)\n",
    "    features_t[5:]=arrive_tt\n",
    "    features_t['max_interval_tt']=interval_tt.max()\n",
    "    features_t['mean_interval_tt']=interval_tt.mean()\n",
    "    features_t['mean_interval_fhk_tt'] = interval_tt[:math.ceil(k/2)].mean() # mean of first half k interval\n",
    "    features_t['mean_interval_lhk_tt'] = interval_tt[math.ceil(k/2):].mean() # mean of last half k interval\n",
    "    return  features_t\n",
    "\n",
    "def extract_features_wt(features_t,repo,origin,k):\n",
    "    arrive_wt = repo.arrive_wt[repo['w_id']==features_t.name]\n",
    "    interval_wt = arrive_wt - shift(arrive_wt,1,cval=0)\n",
    "    features_t[5:]=arrive_wt\n",
    "    post_time = origin_xx.loc[features_t.name].time\n",
    "    features_t['post_wt'] = post_time.hour*3600 + post_time.minute*60 + post_time.second\n",
    "    features_t['max_interval_wt']=interval_wt.max()\n",
    "    features_t['mean_interval_wt']=interval_wt.mean()\n",
    "    features_t['mean_interval_fhk_wt'] = interval_wt[:math.ceil(k/2)].mean() # mean of first half k interval\n",
    "    features_t['mean_interval_lhk_wt'] = interval_wt[math.ceil(k/2):].mean() # mean of last half k interval\n",
    "    return  features_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin:  4160 \n repo:  312000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin:  5199 \n repo:  389925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin:  16640 \n repo:  1248000\n"
     ]
    }
   ],
   "source": [
    "repo_str = ['repo_vali','repo_test','repo_train']\n",
    "origin_str = ['origin_vali','origin_test','origin_train']\n",
    "\n",
    "for i in range(3):\n",
    "    origin_xx = pd.read_csv(base_path+'\\\\samples\\\\'+origin_str[i]+'_tt.csv',\n",
    "                     sep='\\001',\n",
    "                     encoding='utf-8',\n",
    "                     index_col='w_id',\n",
    "                     quoting=3)\n",
    "    repo_xx = pd.read_csv(base_path+'\\\\samples\\\\'+repo_str[i]+'_k75_tt.csv',\n",
    "                    sep='\\001',\n",
    "                    encoding='utf-8',\n",
    "                    quoting=3).fillna(value='', axis=1)\n",
    "    print('origin: ', len(origin_xx), '\\n', 'repo: ', len(repo_xx))\n",
    "    # 只取datetime中的time\n",
    "    origin_xx.time = [t.time() for t in pd.to_datetime(origin_xx.time)]\n",
    "    k = 75\n",
    "    tt_columns = ['post_tt','max_interval_tt','mean_interval_tt','mean_interval_fhk_tt','mean_interval_lhk_tt']+['arrive_tt_' + str(i) for i in range(k)]\n",
    "    features_t = pd.DataFrame(index=origin_xx.index, columns=tt_columns)\n",
    "    features_t = features_t.apply(extract_features_tt,axis=1,repo=repo_xx,k=k)\n",
    "    features_t['post_tt'] = origin_xx.post_tt\n",
    "    features_t.to_csv(base_path + '\\\\features\\\\features_t_'+repo_str[i].split('_')[1]+'_tt.csv',\n",
    "                        index_label='w_id',\n",
    "                        sep='\\001',\n",
    "                        encoding='utf-8',\n",
    "                        quoting=3)\n",
    "    \n",
    "    wt_columns = ['post_wt','max_interval_wt','mean_interval_wt','mean_interval_fhk_wt','mean_interval_lhk_wt']+['arrive_wt_' + str(i) for i in range(k)]\n",
    "    features_t = pd.DataFrame(index=origin_xx.index, columns=wt_columns)\n",
    "    features_t = features_t.apply(extract_features_wt,axis=1,repo=repo_xx,origin=origin_xx,k=k)\n",
    "     \n",
    "    features_t.to_csv(base_path + '\\\\features\\\\features_t_'+repo_str[i].split('_')[1]+'_wt.csv',\n",
    "                        index_label='w_id',\n",
    "                        sep='\\001',\n",
    "                        encoding='utf-8',\n",
    "                        quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}